# vLLM Multi-Node LLM inference service for MeluXina
# Uses tensor parallelism across multiple GPUs/nodes for large models
# Example: Llama-2-70B or Mixtral-8x7B across 4 GPUs

name: vllm-singlenode
description: vLLM multi-node inference with tensor parallelism for large models
image: docker://vllm/vllm-openai:v0.6.3.post1

resources:
  cpu_cores: 8
  memory_gb: 128
  gpu_count: 1
  disk_gb: 200
  nodes: 1 
  ntasks: 1  # 1 task per node
  ntasks_per_node: 1

ports:
  - container_port: 8000
    host_port: 8000
    protocol: tcp

environment:
  VLLM_HOST: "0.0.0.0"
  VLLM_PORT: "8000"
  HF_HOME: "/root/.cache/huggingface"
  # Multi-node communication
  NCCL_DEBUG: "INFO"
  NCCL_IB_DISABLE: "0"
  NCCL_SOCKET_IFNAME: "ib0"
  # Tensor parallelism configuration
  VLLM_WORKER_MULTIPROC_METHOD: "spawn"

volumes:
  # Project scratch directory for persistent model storage
  - host_path: /project/scratch/$SLURM_JOB_ACCOUNT/team-5/vllm
    container_path: /root/.cache/huggingface
    readonly: false

healthcheck:
  endpoint: /health
  interval_seconds: 20
  timeout_seconds: 15
  retries: 3
  initial_delay: 120  # Multi-node setup takes longer

# Command executed INSIDE the Apptainer container
command:
  - /bin/bash
  - -c
  - |
    set -e

    echo "========================================="
    echo "vLLM Multi-Node Service Starting"
    echo "========================================="
    echo "Job ID: ${SLURM_JOB_ID:-unknown}"
    echo "Hostname: $(hostname)"
    echo "Date: $(date)"
    echo "Node Rank: ${NODE_RANK:-0}"
    echo "Master Node: ${MASTER_NODE:-unknown}"
    echo "Total Nodes: ${SLURM_JOB_NUM_NODES:-1}"
    echo "GPUs per Node: 2"
    echo "Total GPUs: 4"
    echo "vLLM Version: v0.6.3.post1"
    echo "========================================="

    # Check GPU availability on this node
    echo ""
    echo "Checking GPU availability on $(hostname)..."
    if command -v nvidia-smi >/dev/null 2>&1; then
        nvidia-smi --query-gpu=index,name,memory.total --format=csv,noheader
        GPU_COUNT=$(nvidia-smi --query-gpu=name --format=csv,noheader | wc -l)
        echo "✓ Found $GPU_COUNT GPU(s) on this node"
    else
        echo "Warning: nvidia-smi not found"
        GPU_COUNT=0
    fi

    # Determine if this is the master node based on NODE_RANK (set by host script)
    if [ "${NODE_RANK:-0}" = "0" ]; then
        IS_MASTER=true
        echo "✓ This is the MASTER node (rank 0)"
    else
        IS_MASTER=false
        echo "✓ This is a WORKER node (rank ${NODE_RANK})"
    fi

    echo ""
    echo "Note: This recipe uses LOCAL GPUs on master node only."
    echo "True multi-node tensor parallelism requires Ray cluster setup."
    echo ""

    if [ "$IS_MASTER" = true ]; then
        echo ""
        echo "========================================="
        echo "MASTER NODE: Starting vLLM Server"
        echo "========================================="
        
        if [ "$GPU_COUNT" -eq "0" ]; then
            echo "✗ No GPUs found on master node"
            exit 1
        fi

        echo "Starting vLLM with $GPU_COUNT GPUs on master node..."
        echo "Model: mistralai/Mistral-7B-Instruct-v0.2"

        # Start vLLM server with tensor parallelism across local GPUs
        python3 -m vllm.entrypoints.openai.api_server \
            --model mistralai/Mistral-7B-Instruct-v0.2 \
            --host 0.0.0.0 \
            --port 8000 \
            --tensor-parallel-size $GPU_COUNT \
            --gpu-memory-utilization 0.9 \
            --max-model-len 8192 \
            --dtype auto \
            --trust-remote-code \
            --disable-log-requests &

        SERVER_PID=$!
        echo "✓ Server PID: $SERVER_PID"

        # Cleanup function
        cleanup() {
            echo ""
            echo "Shutting down vLLM server..."
            kill $SERVER_PID 2>/dev/null || true
            wait $SERVER_PID 2>/dev/null || true
            echo "✓ Server stopped"
        }
        trap cleanup EXIT INT TERM

        # Wait for server initialization
        echo "Waiting for server to initialize (120 seconds)..."
        sleep 120

        if ! kill -0 $SERVER_PID 2>/dev/null; then
            echo "✗ Server process died during startup"
            echo "Check logs for details"
            exit 1
        fi

        # Display connection information
        COMPUTE_NODE=$(hostname)
        echo ""
        echo "========================================="
        echo "vLLM Server Ready!"
        echo "========================================="
        echo "OpenAI-compatible API: http://${COMPUTE_NODE}:8000/v1"
        echo "Tensor Parallel Size: $GPU_COUNT GPUs"
        echo ""
        echo "Test from login node:"
        echo "  curl http://${COMPUTE_NODE}:8000/health"
        echo "  curl http://${COMPUTE_NODE}:8000/v1/models"
        echo ""
        echo "Example inference request:"
        echo "  curl http://${COMPUTE_NODE}:8000/v1/completions \\"
        echo "    -H 'Content-Type: application/json' \\"
        echo "    -d '{\"model\": \"mistralai/Mistral-7B-Instruct-v0.2\", \"prompt\": \"Explain tensor parallelism:\", \"max_tokens\": 200}'"
        echo ""
        echo "Job will run until time limit or manual cancellation"
        echo "========================================="

        # Keep container alive - wait for server process
        wait $SERVER_PID
        EXIT_CODE=$?
        echo ""
        echo "Server exited with code: $EXIT_CODE"
        exit $EXIT_CODE

    else
        echo ""
        echo "========================================="
        echo "WORKER NODE: Idle"
        echo "========================================="
        echo "This node is allocated but not actively used"
        echo "For true multi-node parallelism, Ray setup is required"
        echo ""
        echo "Sleeping until job completion..."
        
        # Worker nodes just sleep until the job ends
        sleep infinity
    fi

working_dir: /workspace
